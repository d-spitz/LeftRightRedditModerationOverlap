{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "\n",
    "# simple file to grab rules lists \n",
    "\n",
    "rightrulesfile = \"../../subredditdata/rules/rightrules.json\"\n",
    "rightsubredditsfile = \"../../input/rightsubreddits.json\"\n",
    "\n",
    "# leftrulesfile = \"../../subredditdata/rules/leftrules.json\"\n",
    "# leftsubredditsfile = \"../../input/leftsubreddits.json\"\n",
    "\n",
    "output = {}\n",
    "\n",
    "# Quarantined subreddits require an additional entry function\n",
    "known_quarantined = {\"TheRedPill\"}\n",
    "\n",
    "with open(rightsubredditsfile, 'r') as subs, open(rightrulesfile, 'w') as of:\n",
    "    subreddit_list = json.load(subs)[\"subreddits\"]\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"REDACTED\",\n",
    "        client_secret=\"REDACTED\",\n",
    "        user_agent=\"REDACTED\",\n",
    "        username=\"REDACTED\",\n",
    "        password=\"REDACTED\"\n",
    "    )\n",
    "    for sub_name in subreddit_list:\n",
    "        try:\n",
    "            current_sub = reddit.subreddit(sub_name)\n",
    "            if current_sub in known_quarantined:\n",
    "                current_sub.quaran.opt_in()\n",
    "            \n",
    "            # Rules scraping\n",
    "            rules_list = {}\n",
    "            for r in current_sub.rules:\n",
    "                rule_no = \"Rule \" + str(r.priority)\n",
    "                rules_list[rule_no] = {\"priority\": r.priority,\n",
    "                                    \"short_name\": r.short_name,\n",
    "                                    \"description\": r.description,\n",
    "                                    \"created_utc\": r.created_utc,\n",
    "                                    \"kind\": r.kind,\n",
    "                                    \"violation_reason\": r.violation_reason\n",
    "                                    }\n",
    "            output[sub_name] = rules_list\n",
    "        except:\n",
    "            print(\"error when scraping\", sub_name)\n",
    "    json.dump(output, of, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
